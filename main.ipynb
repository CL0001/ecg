{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Desease prediction by ECG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import wfdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"./ecg_resources/data\"\n",
    "label_path = \"./ecg_resources/annotations.csv\"\n",
    "output_path = \"./data\"\n",
    "\n",
    "min_length = 2200 # this is length of the shortest timestamp\n",
    "batch = []\n",
    "\n",
    "labels = np.loadtxt(label_path, delimiter=',', skiprows=1, dtype=str)\n",
    "trimed_labels = np.delete(labels, [0, 1, 2, 3, -1], axis=1)\n",
    "casted_labels = trimed_labels.astype(np.float32)\n",
    "\n",
    "filename = \"batch\"\n",
    "file_group = 1\n",
    "\n",
    "os.makedirs(output_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while file_group <= 39_999:\n",
    "    record_name = f\"TNMG{file_group}_N1\"\n",
    "    print(f\"Processing record: {record_name}\")\n",
    "    try:\n",
    "        record_signal = wfdb.rdrecord(os.path.join(data_path, record_name)).p_signal\n",
    "\n",
    "        if record_signal.shape[0] > min_length:\n",
    "            trimmed_signal = record_signal[:min_length, :]\n",
    "        else:\n",
    "            trimmed_signal = record_signal\n",
    "\n",
    "        batch.append(trimmed_signal)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Can't load file: {record_name}, error: {e}\\n\")\n",
    "        file_group += 1\n",
    "        continue\n",
    "\n",
    "    if len(batch) == 100:\n",
    "        numpy_array = np.array(batch, dtype=np.float32)\n",
    "        trimmed_labels = casted_labels[:100]\n",
    "\n",
    "        np.savez(os.path.join(output_path, f\"{filename}-{int(file_group / 100)}.npz\"),\n",
    "                 signals=numpy_array, labels=trimmed_labels)\n",
    "\n",
    "        print(f\"Batch saved as {filename}-{int(file_group / 100)}.npz\\n\")\n",
    "\n",
    "        batch = []\n",
    "        casted_labels = casted_labels[100:]\n",
    "\n",
    "    file_group += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a PyTorch dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.5.1+cu124'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = \"./data\"\n",
    "\n",
    "data = []\n",
    "labels = []\n",
    "\n",
    "for i, file in enumerate(os.listdir(input_path)):\n",
    "    print(f\"{i}. processing file: {file}\")\n",
    "    file_path = os.path.join(input_path, file)\n",
    "\n",
    "    record = np.load(file_path)\n",
    "    signals = record[\"signals\"]\n",
    "    label = record[\"labels\"]\n",
    "\n",
    "    data.append(signals)\n",
    "    labels.append(label)\n",
    "\n",
    "data = np.array(data)\n",
    "labels = np.array(labels)\n",
    "\n",
    "torch.save({'data': data, 'labels': labels}, 'dataset.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class ECGDataset(Dataset):\n",
    "    def __init__(self, data, labels):\n",
    "        self.data = torch.tensor(data, dtype=torch.float32)\n",
    "        self.labels = torch.tensor(labels, dtype=torch.float32)\n",
    "\n",
    "        self.data = self.data.view(-1, 2200 * 8)\n",
    "        self.labels = self.labels.view(-1, 6)\n",
    "\n",
    "        self.num_samples = self.data.shape[0]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_samples\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = self.data[idx]\n",
    "        y = self.labels[idx]\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class MultiLabelClassifier(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(MultiLabelClassifier, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "input_dim = 2200 * 8\n",
    "hidden_dim = 128\n",
    "output_dim = 6\n",
    "\n",
    "model = MultiLabelClassifier(input_dim, hidden_dim, output_dim).to(device)\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "dataset_load = torch.load(\"dataset.pt\", weights_only=False)\n",
    "dataset = ECGDataset(dataset_load[\"data\"], dataset_load[\"labels\"])\n",
    "\n",
    "data_loader = DataLoader(dataset, batch_size=32, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100 | Train Loss: 0.3363, Train Acc: 0.9710 | Test Loss: 0.2585, Test Acc: 0.9767\n",
      "Epoch 2/100 | Train Loss: 0.2820, Train Acc: 0.9765 | Test Loss: 1.2255, Test Acc: 0.9612\n",
      "Epoch 3/100 | Train Loss: 0.2638, Train Acc: 0.9763 | Test Loss: 0.2426, Test Acc: 0.9778\n",
      "Epoch 4/100 | Train Loss: 0.2510, Train Acc: 0.9768 | Test Loss: 0.2279, Test Acc: 0.9780\n",
      "Epoch 5/100 | Train Loss: 0.2510, Train Acc: 0.9770 | Test Loss: 0.2321, Test Acc: 0.9788\n",
      "Epoch 6/100 | Train Loss: 0.2636, Train Acc: 0.9774 | Test Loss: 0.2591, Test Acc: 0.9791\n",
      "Epoch 7/100 | Train Loss: 0.2885, Train Acc: 0.9778 | Test Loss: 0.2713, Test Acc: 0.9797\n",
      "Epoch 8/100 | Train Loss: 0.2775, Train Acc: 0.9785 | Test Loss: 0.2980, Test Acc: 0.9809\n",
      "Epoch 9/100 | Train Loss: 0.2859, Train Acc: 0.9797 | Test Loss: 0.2692, Test Acc: 0.9821\n",
      "Epoch 10/100 | Train Loss: 0.2854, Train Acc: 0.9807 | Test Loss: 0.2712, Test Acc: 0.9833\n",
      "Epoch 11/100 | Train Loss: 0.2974, Train Acc: 0.9814 | Test Loss: 0.2908, Test Acc: 0.9838\n",
      "Epoch 12/100 | Train Loss: 0.3010, Train Acc: 0.9823 | Test Loss: 0.2825, Test Acc: 0.9855\n",
      "Epoch 13/100 | Train Loss: 0.3011, Train Acc: 0.9838 | Test Loss: 0.2772, Test Acc: 0.9871\n",
      "Epoch 14/100 | Train Loss: 0.3191, Train Acc: 0.9842 | Test Loss: 0.3114, Test Acc: 0.9862\n",
      "Epoch 15/100 | Train Loss: 0.3139, Train Acc: 0.9850 | Test Loss: 0.3290, Test Acc: 0.9867\n",
      "Epoch 16/100 | Train Loss: 0.3127, Train Acc: 0.9860 | Test Loss: 0.2859, Test Acc: 0.9888\n",
      "Epoch 17/100 | Train Loss: 0.3120, Train Acc: 0.9869 | Test Loss: 0.2993, Test Acc: 0.9886\n",
      "Epoch 18/100 | Train Loss: 0.3282, Train Acc: 0.9862 | Test Loss: 0.3364, Test Acc: 0.9848\n",
      "Epoch 19/100 | Train Loss: 0.3110, Train Acc: 0.9875 | Test Loss: 0.3009, Test Acc: 0.9891\n",
      "Epoch 20/100 | Train Loss: 0.3121, Train Acc: 0.9879 | Test Loss: 0.2980, Test Acc: 0.9896\n",
      "Epoch 21/100 | Train Loss: 0.3147, Train Acc: 0.9879 | Test Loss: 0.3102, Test Acc: 0.9891\n",
      "Epoch 22/100 | Train Loss: 0.3157, Train Acc: 0.9880 | Test Loss: 0.3149, Test Acc: 0.9881\n",
      "Epoch 23/100 | Train Loss: 0.3110, Train Acc: 0.9884 | Test Loss: 0.2943, Test Acc: 0.9900\n",
      "Epoch 24/100 | Train Loss: 0.3062, Train Acc: 0.9892 | Test Loss: 0.2954, Test Acc: 0.9902\n",
      "Epoch 25/100 | Train Loss: 0.3209, Train Acc: 0.9884 | Test Loss: 0.3133, Test Acc: 0.9896\n",
      "Epoch 26/100 | Train Loss: 0.3164, Train Acc: 0.9887 | Test Loss: 0.3038, Test Acc: 0.9899\n",
      "Epoch 27/100 | Train Loss: 0.3284, Train Acc: 0.9883 | Test Loss: 0.3057, Test Acc: 0.9896\n",
      "Epoch 28/100 | Train Loss: 0.3218, Train Acc: 0.9886 | Test Loss: 0.2985, Test Acc: 0.9904\n",
      "Epoch 29/100 | Train Loss: 0.3126, Train Acc: 0.9889 | Test Loss: 0.2984, Test Acc: 0.9902\n",
      "Epoch 30/100 | Train Loss: 0.3125, Train Acc: 0.9891 | Test Loss: 0.3005, Test Acc: 0.9904\n",
      "Epoch 31/100 | Train Loss: 0.3151, Train Acc: 0.9892 | Test Loss: 0.3090, Test Acc: 0.9900\n",
      "Epoch 32/100 | Train Loss: 0.3061, Train Acc: 0.9896 | Test Loss: 0.3000, Test Acc: 0.9903\n",
      "Epoch 33/100 | Train Loss: 0.3209, Train Acc: 0.9887 | Test Loss: 0.3132, Test Acc: 0.9897\n",
      "Epoch 34/100 | Train Loss: 0.3214, Train Acc: 0.9888 | Test Loss: 0.3196, Test Acc: 0.9896\n",
      "Epoch 35/100 | Train Loss: 0.3185, Train Acc: 0.9893 | Test Loss: 0.3144, Test Acc: 0.9901\n",
      "Epoch 36/100 | Train Loss: 0.3132, Train Acc: 0.9894 | Test Loss: 0.2987, Test Acc: 0.9905\n",
      "Epoch 37/100 | Train Loss: 0.3212, Train Acc: 0.9891 | Test Loss: 0.3030, Test Acc: 0.9885\n",
      "Epoch 38/100 | Train Loss: 0.3241, Train Acc: 0.9892 | Test Loss: 0.3081, Test Acc: 0.9904\n",
      "Epoch 39/100 | Train Loss: 0.3165, Train Acc: 0.9897 | Test Loss: 0.3012, Test Acc: 0.9907\n",
      "Epoch 40/100 | Train Loss: 0.3084, Train Acc: 0.9898 | Test Loss: 0.3382, Test Acc: 0.9893\n",
      "Epoch 41/100 | Train Loss: 0.3112, Train Acc: 0.9895 | Test Loss: 0.3160, Test Acc: 0.9891\n",
      "Epoch 42/100 | Train Loss: 0.3208, Train Acc: 0.9894 | Test Loss: 0.3105, Test Acc: 0.9900\n",
      "Epoch 43/100 | Train Loss: 0.3117, Train Acc: 0.9894 | Test Loss: 0.3617, Test Acc: 0.9856\n",
      "Epoch 44/100 | Train Loss: 0.3174, Train Acc: 0.9894 | Test Loss: 0.2985, Test Acc: 0.9909\n",
      "Epoch 45/100 | Train Loss: 0.3056, Train Acc: 0.9900 | Test Loss: 0.3011, Test Acc: 0.9907\n",
      "Epoch 46/100 | Train Loss: 0.3202, Train Acc: 0.9894 | Test Loss: 0.3152, Test Acc: 0.9901\n",
      "Epoch 47/100 | Train Loss: 0.3153, Train Acc: 0.9898 | Test Loss: 0.3040, Test Acc: 0.9908\n",
      "Epoch 48/100 | Train Loss: 0.3068, Train Acc: 0.9899 | Test Loss: 0.2962, Test Acc: 0.9908\n",
      "Epoch 49/100 | Train Loss: 0.3153, Train Acc: 0.9898 | Test Loss: 0.3077, Test Acc: 0.9905\n",
      "Epoch 50/100 | Train Loss: 0.3199, Train Acc: 0.9893 | Test Loss: 0.3048, Test Acc: 0.9908\n",
      "Epoch 51/100 | Train Loss: 0.3259, Train Acc: 0.9895 | Test Loss: 0.3082, Test Acc: 0.9903\n",
      "Epoch 52/100 | Train Loss: 0.3085, Train Acc: 0.9898 | Test Loss: 0.3193, Test Acc: 0.9901\n",
      "Epoch 53/100 | Train Loss: 0.3081, Train Acc: 0.9901 | Test Loss: 0.3029, Test Acc: 0.9908\n",
      "Epoch 54/100 | Train Loss: 0.3051, Train Acc: 0.9899 | Test Loss: 0.3004, Test Acc: 0.9909\n",
      "Epoch 55/100 | Train Loss: 0.3126, Train Acc: 0.9897 | Test Loss: 0.3119, Test Acc: 0.9903\n",
      "Epoch 56/100 | Train Loss: 0.3141, Train Acc: 0.9895 | Test Loss: 0.3076, Test Acc: 0.9906\n",
      "Epoch 57/100 | Train Loss: 0.3139, Train Acc: 0.9900 | Test Loss: 0.3134, Test Acc: 0.9901\n",
      "Epoch 58/100 | Train Loss: 0.3164, Train Acc: 0.9899 | Test Loss: 0.3002, Test Acc: 0.9911\n",
      "Epoch 59/100 | Train Loss: 0.3046, Train Acc: 0.9905 | Test Loss: 0.2986, Test Acc: 0.9909\n",
      "Epoch 60/100 | Train Loss: 0.3308, Train Acc: 0.9893 | Test Loss: 0.3117, Test Acc: 0.9907\n",
      "Epoch 61/100 | Train Loss: 0.3116, Train Acc: 0.9900 | Test Loss: 0.3089, Test Acc: 0.9902\n",
      "Epoch 62/100 | Train Loss: 0.3044, Train Acc: 0.9904 | Test Loss: 0.2976, Test Acc: 0.9912\n",
      "Epoch 63/100 | Train Loss: 0.3105, Train Acc: 0.9902 | Test Loss: 0.3096, Test Acc: 0.9903\n",
      "Epoch 64/100 | Train Loss: 0.3044, Train Acc: 0.9901 | Test Loss: 0.3256, Test Acc: 0.9899\n",
      "Epoch 65/100 | Train Loss: 0.3256, Train Acc: 0.9895 | Test Loss: 0.3169, Test Acc: 0.9902\n",
      "Epoch 66/100 | Train Loss: 0.3154, Train Acc: 0.9899 | Test Loss: 0.3158, Test Acc: 0.9905\n",
      "Epoch 67/100 | Train Loss: 0.3102, Train Acc: 0.9902 | Test Loss: 0.3128, Test Acc: 0.9902\n",
      "Epoch 68/100 | Train Loss: 0.3171, Train Acc: 0.9898 | Test Loss: 0.3071, Test Acc: 0.9909\n",
      "Epoch 69/100 | Train Loss: 0.3163, Train Acc: 0.9902 | Test Loss: 0.3062, Test Acc: 0.9908\n",
      "Epoch 70/100 | Train Loss: 0.3184, Train Acc: 0.9898 | Test Loss: 0.2975, Test Acc: 0.9911\n",
      "Epoch 71/100 | Train Loss: 0.3279, Train Acc: 0.9896 | Test Loss: 0.3064, Test Acc: 0.9908\n",
      "Epoch 72/100 | Train Loss: 0.3139, Train Acc: 0.9902 | Test Loss: 0.3044, Test Acc: 0.9911\n",
      "Epoch 73/100 | Train Loss: 0.3063, Train Acc: 0.9905 | Test Loss: 0.3085, Test Acc: 0.9904\n",
      "Epoch 74/100 | Train Loss: 0.3128, Train Acc: 0.9901 | Test Loss: 0.3001, Test Acc: 0.9911\n",
      "Epoch 75/100 | Train Loss: 0.3060, Train Acc: 0.9902 | Test Loss: 0.2956, Test Acc: 0.9914\n",
      "Epoch 76/100 | Train Loss: 0.3006, Train Acc: 0.9904 | Test Loss: 0.2995, Test Acc: 0.9910\n",
      "Epoch 77/100 | Train Loss: 0.3137, Train Acc: 0.9900 | Test Loss: 0.3040, Test Acc: 0.9906\n",
      "Epoch 78/100 | Train Loss: 0.3037, Train Acc: 0.9905 | Test Loss: 0.2973, Test Acc: 0.9913\n",
      "Epoch 79/100 | Train Loss: 0.3018, Train Acc: 0.9903 | Test Loss: 0.3014, Test Acc: 0.9911\n",
      "Epoch 80/100 | Train Loss: 0.3182, Train Acc: 0.9901 | Test Loss: 0.3342, Test Acc: 0.9901\n",
      "Epoch 81/100 | Train Loss: 0.3100, Train Acc: 0.9903 | Test Loss: 0.2957, Test Acc: 0.9914\n",
      "Epoch 82/100 | Train Loss: 0.3008, Train Acc: 0.9905 | Test Loss: 0.2929, Test Acc: 0.9913\n",
      "Epoch 83/100 | Train Loss: 0.2992, Train Acc: 0.9908 | Test Loss: 0.2930, Test Acc: 0.9914\n",
      "Epoch 84/100 | Train Loss: 0.3169, Train Acc: 0.9900 | Test Loss: 0.3122, Test Acc: 0.9907\n",
      "Epoch 85/100 | Train Loss: 0.3190, Train Acc: 0.9899 | Test Loss: 0.3013, Test Acc: 0.9909\n",
      "Epoch 86/100 | Train Loss: 0.3039, Train Acc: 0.9906 | Test Loss: 0.3093, Test Acc: 0.9911\n",
      "Epoch 87/100 | Train Loss: 0.3081, Train Acc: 0.9905 | Test Loss: 0.2973, Test Acc: 0.9914\n",
      "Epoch 88/100 | Train Loss: 0.3013, Train Acc: 0.9907 | Test Loss: 0.2979, Test Acc: 0.9914\n",
      "Epoch 89/100 | Train Loss: 0.3144, Train Acc: 0.9904 | Test Loss: 0.3008, Test Acc: 0.9910\n",
      "Epoch 90/100 | Train Loss: 0.3154, Train Acc: 0.9901 | Test Loss: 0.3095, Test Acc: 0.9906\n",
      "Epoch 91/100 | Train Loss: 0.3154, Train Acc: 0.9902 | Test Loss: 0.2980, Test Acc: 0.9914\n",
      "Epoch 92/100 | Train Loss: 0.3028, Train Acc: 0.9908 | Test Loss: 0.2970, Test Acc: 0.9914\n",
      "Epoch 93/100 | Train Loss: 0.3077, Train Acc: 0.9906 | Test Loss: 0.3159, Test Acc: 0.9908\n",
      "Epoch 94/100 | Train Loss: 0.3078, Train Acc: 0.9904 | Test Loss: 0.3013, Test Acc: 0.9913\n",
      "Epoch 95/100 | Train Loss: 0.3136, Train Acc: 0.9901 | Test Loss: 0.3054, Test Acc: 0.9911\n",
      "Epoch 96/100 | Train Loss: 0.3048, Train Acc: 0.9903 | Test Loss: 0.2990, Test Acc: 0.9911\n",
      "Epoch 97/100 | Train Loss: 0.3014, Train Acc: 0.9905 | Test Loss: 0.3285, Test Acc: 0.9901\n",
      "Epoch 98/100 | Train Loss: 0.3068, Train Acc: 0.9907 | Test Loss: 0.2956, Test Acc: 0.9914\n",
      "Epoch 99/100 | Train Loss: 0.3024, Train Acc: 0.9909 | Test Loss: 0.2971, Test Acc: 0.9909\n",
      "Epoch 100/100 | Train Loss: 0.3115, Train Acc: 0.9902 | Test Loss: 0.3067, Test Acc: 0.9904\n"
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_train_loss = 0\n",
    "    train_correct = 0\n",
    "    train_total = 0\n",
    "\n",
    "    for inputs, labels in data_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        labels = labels.float()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_train_loss += loss.item()\n",
    "\n",
    "        predicted = (outputs > 0.5).float()\n",
    "        train_correct += (predicted == labels).sum().item()\n",
    "        train_total += labels.numel()\n",
    "\n",
    "    avg_train_loss = total_train_loss / len(data_loader)\n",
    "    train_accuracy = train_correct / train_total\n",
    "\n",
    "\n",
    "    model.eval()\n",
    "    total_test_loss = 0\n",
    "    test_correct = 0\n",
    "    test_total = 0\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        for inputs, labels in data_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            labels = labels.float()\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            total_test_loss += loss.item()\n",
    "\n",
    "            predicted = (outputs > 0.5).float()\n",
    "            test_correct += (predicted == labels).sum().item()\n",
    "            test_total += labels.numel()\n",
    "\n",
    "    avg_test_loss = total_test_loss / len(data_loader)\n",
    "    test_accuracy = test_correct / test_total\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{epochs} | Train Loss: {avg_train_loss:.4f}, Train Acc: {train_accuracy:.4f} | Test Loss: {avg_test_loss:.4f}, Test Acc: {test_accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"ecg_model.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Model Prediction Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_pred(vals, ans):\n",
    "    model.eval()\n",
    "    with torch.inference_mode():\n",
    "        vals = vals.clone().detach().float().to(device)\n",
    "\n",
    "        vals = vals.view(1, -1)\n",
    "\n",
    "        pred = model(vals)\n",
    "        probabilities = pred.cpu().numpy()\n",
    "        predicted_labels = (pred > 0.5).int().cpu().numpy()\n",
    "\n",
    "        print(f\"\\nProbabilities: {probabilities}, \\nPrediction: {predicted_labels}, \\nAnswer: {ans} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Probabilities: [[6.8153909e-08 2.4420189e-07 5.6282011e-17 1.3305446e-13 8.2911463e-08\n",
      "  1.9636718e-07]], \n",
      "Prediction: [[0 0 0 0 0 0]], \n",
      "Answer: [0. 0. 0. 0. 0. 0.] \n",
      "\n",
      "\n",
      "Probabilities: [[3.2594273e-25 5.2787104e-21 6.1008863e-14 1.0344354e-22 1.0000000e+00\n",
      "  9.3258457e-12]], \n",
      "Prediction: [[0 0 0 0 1 0]], \n",
      "Answer: [0. 0. 0. 0. 1. 0.] \n",
      "\n",
      "\n",
      "Probabilities: [[0. 0. 0. 0. 0. 0.]], \n",
      "Prediction: [[0 0 0 0 0 0]], \n",
      "Answer: [1. 0. 0. 0. 0. 0.] \n",
      "\n",
      "\n",
      "Probabilities: [[0.0000000e+00 3.2699278e-24 1.0000000e+00 1.2412947e-32 0.0000000e+00\n",
      "  1.1415087e-38]], \n",
      "Prediction: [[0 0 1 0 0 0]], \n",
      "Answer: [0. 0. 1. 0. 0. 0.] \n",
      "\n",
      "\n",
      "Probabilities: [[0. 0. 0. 0. 0. 0.]], \n",
      "Prediction: [[0 0 0 0 0 0]], \n",
      "Answer: [0. 0. 0. 0. 0. 0.] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_model = MultiLabelClassifier(input_dim, hidden_dim, output_dim).to(device)\n",
    "test_model.load_state_dict(torch.load(\"ecg_model.pth\", weights_only=False, map_location=device))\n",
    "\n",
    "sample_0 = dataset.data[0]\n",
    "sample_1 = dataset.data[1]\n",
    "sample_2 = dataset.data[2]\n",
    "sample_3 = dataset.data[3]\n",
    "sample_4 = dataset.data[4]\n",
    "\n",
    "label_0 = dataset.labels[0].cpu().numpy()\n",
    "label_1 = dataset.labels[1].cpu().numpy()\n",
    "label_2 = dataset.labels[2].cpu().numpy()\n",
    "label_3 = dataset.labels[3].cpu().numpy()\n",
    "label_4 = dataset.labels[4].cpu().numpy()\n",
    "\n",
    "\n",
    "print_pred(sample_0, label_0)\n",
    "print_pred(sample_1, label_1)\n",
    "print_pred(sample_2, label_2)\n",
    "print_pred(sample_3, label_3)\n",
    "print_pred(sample_4, label_4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
